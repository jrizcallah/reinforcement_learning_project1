{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first attempt at reinforcement learning. This project is quite similar to the one described in the following article: \n",
    "    https://www.mlq.ai/deep-reinforcement-learning-for-trading-with-tensorflow-2-0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (20.3.3)\n",
      "Requirement already satisfied: pandas-datareader in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: lxml in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas-datareader) (4.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas-datareader) (1.0.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas-datareader) (2.24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->pandas-datareader) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas>=0.23->pandas-datareader) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pandas-datareader) (1.25.9)\n",
      "Requirement already satisfied: tqdm in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (4.47.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-macosx_10_11_x86_64.whl (175.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 175.5 MB 49.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 60.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.4-cp38-cp38-macosx_10_9_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 27.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (49.2.0.post20200714)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 44.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/johnrizcallah/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 28.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 7.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 17.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 26.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=11e01e3874689e6d5b3b46a00047d66df9d0afd0178df873ca632734a0c4df11\n",
      "  Stored in directory: /Users/johnrizcallah/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl size=32630 sha256=56b9fd4ab56304bd166f5fd6fbd66e890f14d22ce7ff36b943698dfbdf17c26f\n",
      "  Stored in directory: /Users/johnrizcallah/Library/Caches/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, google-auth, wheel, tensorboard-plugin-wit, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.4 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pandas-datareader\n",
    "!pip install tqdm\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Deep Q-Learning Trader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual \"deep learning\" part; it is object-based. \n",
    "\n",
    "I am going to create an AI_Trader() class that will learn to trade profitably (hopefully, at least). \n",
    "\n",
    "This AI_Trader object needs some definition...\n",
    "* The only actions it can take are Buy, Hold, or Sell\n",
    "* It can 'remember' 2000 events\n",
    "* It will need an inventory of stocks it owns\n",
    "* It will need a risk-aversion parameter, $\\gamma$, to help maximize the long-term reward\n",
    "* The $\\epsilon$ parameter to decide whether to use the model or randomize the action it takes\n",
    "* Over time, the AI_Trader should stop randomizing and obey the model, so $\\epsilon$ should decrease\n",
    "* If $\\epsilon$ is going to decrease, we need to define the speed at which it decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "    \n",
    "    def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_final = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model that the AI_Trader is going to use to learn how to make profitable trades. \n",
    "\n",
    "In this instance, it will be be a Neural Network with 4 Dense Layers that outputs the expected utility of talking any of the three possible actions Buy, Hold, or Sell. Since the AI_Trader learns over time, we want the model to start at time $t$, then the AI_Trader takes an action, then new data arrives at time $t+1$ and, the AI_Trader is rewarded/punished for its action, the model is reformed and the AI_Trader takes an ew action, and so on. So we will need a function that creates a new Neural Network with 4 Layers every time. \n",
    "\n",
    "Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(self):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation='relu')),\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu')),\n",
    "    model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
    "    \n",
    "    #Now we can compile the model. We will use the Adam optimizer and MSE as the loss function.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Trading Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take the state as an input and allow the AI_Trader to take action based on that state. It is the function that *actually does the trading*...can't think of a better way to say that. Hopefully it makes sense.\n",
    "\n",
    "This function will be called **trade**, and will take one argument, **state**. \n",
    "\n",
    "Based on the state, the function will decide if our AI_Trader should do what the model says, or take a random action. Since $\\epsilon$ is the \"learnedness\" of the AI_Trader, we will tell it to perform a random action with probability $\\epsilon$, or follow the model with probability $1=\\epsilon$. In code, this means we draw a random uniform $U \\in [0,1]$, and if  $U > \\epsilon$, follow the model. And of course if $U \\le \\epsilon$ perform a random action.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade(self, state):\n",
    "    # Draw random number and see if it is less than epsilon\n",
    "    if random.random() <= self.epsilon:\n",
    "        # random action\n",
    "        return random.randrange(self.action_space)\n",
    "    \n",
    "    # Get the action from the model\n",
    "    action = self.model.predict(action[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needs a training function that the AI_Trader can learn from. The training function will train the prelimary model on the saved data, then allow the AI_Trader to learn from the performance of the trained model. Step by Step:\n",
    "\n",
    "1. Append the datafrom the AI_Trader's **memory**, in batches\n",
    "2. Get the reward from each batch based on **state**, **next_state**, and the **action** taken\n",
    "3. Set the **target** based on the prediction from the model\n",
    "4. Fit the model with **state** as the independent variable and **target** as the dependent variable\n",
    "5. If the previous $\\epsilon$ is greater than the final $\\epsilon$, let $\\epsilon$ decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(self, batch_size):\n",
    "    # batch starts empty\n",
    "    batch = []\n",
    "    # Cycle through the memory, append batches to the batch list\n",
    "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "        batch.append(self.memory[i])\n",
    "        \n",
    "    # Get the reward from each batch\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "        reward = reward\n",
    "        \n",
    "        if not done:\n",
    "            reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            \n",
    "        target = self.model.predict(state)\n",
    "        target[0][action] = reward\n",
    "    \n",
    "        self.model.fit(state, target, epochs=1, verbose=0)\n",
    "    \n",
    "    if self.epsilon > self.epsilon_final:\n",
    "        self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock data will need to be loaded, preprocessed so that it is in a precise format that the AI_Trader can easily understand, and normalized. This is going to take three functions. They are all pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to normalize the stock prices between 0 and 1\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+math.exp(-x))\n",
    "\n",
    "# This function formats the stock prices like \"(-)$ {price}\"\n",
    "def stocks_price_format(n):\n",
    "    if n <0:\n",
    "        return \"-$ {0:2f}\".format(abs(n))\n",
    "    else:\n",
    "        return \"$ {0:2f}\".format(abs(n))\n",
    "\n",
    "# Load the data from yahoo finance\n",
    "def dataset_loader(stock_name):\n",
    "    dataset = data_reader.DataReader(stock_name, data_source='yahoo')\n",
    "    \n",
    "    start_date = str(dataset.index[0]).split()[0]\n",
    "    end_date = str(dataset.index[1]).split()[0]\n",
    "    close = dataset['Close']\n",
    "    \n",
    "    return close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-12-29    27.184999\n",
       "2015-12-30    26.830000\n",
       "2015-12-31    26.315001\n",
       "2016-01-04    26.337500\n",
       "2016-01-05    25.677500\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loader('AAPL').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AI_Trader needs the **state**.\n",
    "\n",
    "Here is what is happening under the hood, in general terms:\n",
    "* Stock prices are floating point numbers that represent the value of a stock at a point in time\n",
    "* The AI_Trader needs to predict what is going to happen at the next point in time; with the stock price be higher or lower than it is now?\n",
    "* Based on that prediction, the AI_Trader needs to take the best action: buy, sell, or hold.\n",
    "How should the AI_Trader make those predictions? That's the real art here...for this example, we are going to let the AI_Trader use a regresssion model with data from the 5 previous time-steps. \n",
    "\n",
    "Instead of using raw stock prices, we will use the difference in price from one day to the next. Maybe this will all be easier to explain after the code. Meet me on the other side of the next cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_creator(data, timestep, window_size):\n",
    "    starting_id = timestep - window_size + 1\n",
    "    if starting_id >= 0:\n",
    "        windowed_data = data[starting_id:timestep+1]\n",
    "    else:\n",
    "        windowed_data = abs(starting_id) * [data[0]] + list(data[0:timestep+1])\n",
    "    \n",
    "    state = []\n",
    "    for i in range(window_size - 1):\n",
    "        state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
    "        \n",
    "    return np.array([state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. The state_creator function takes in the data, how many timesteps we want, and the window_size. It creates a starting_id that is the starting point of the window being used to create the states. If that starting_id is positive, we grab the data in the window. If the starting_id is negative, we carry the earliest observation back until we have a list of prices that has length of window_size.\n",
    "\n",
    "Then, we find the differences from one timestep to the last and normalize it using the previously defined **sigmoid** function; a difference of zero has the final value of 0.5, negative differences have final values below 0.5 and positive differences have final values greater than 0.5.\n",
    "\n",
    "Let's see what it looks like if we load a dataset for Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-12-29    27.184999\n",
       "2015-12-30    26.830000\n",
       "2015-12-31    26.315001\n",
       "2016-01-04    26.337500\n",
       "2016-01-05    25.677500\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_name = 'AAPL'\n",
    "data = dataset_loader(stock_name)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning: Training the AI_Trader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AI_Trader needs to learn, so we need to train it. Since the state_creator function works with windows, the AI_Trader needs to know the **window_size**; because we train the model in batches, the AI_Trader needs to know the **batch_size**; because the AI_Trader learns by events, it needs to be told how many **episodes** it should train for; because we use the difference in prices rather than raw closing prices, there are N-1 **data_samples** in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "batch_size = 32\n",
    "episodes = 1000\n",
    "data_samples = len(data) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...the AI_Trader class is defined in pieces above. We need to put the whole thing together. That happens in the next cell. Just putting everything together from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "    \n",
    "    def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_final = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        \n",
    "        self.model = self.model_builder()\n",
    "        \n",
    "    def model_builder(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "    \n",
    "        model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu')),\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu')),\n",
    "        model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
    "    \n",
    "        #Now we can compile the model. We will use the Adam optimizer and MSE as the loss function.\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def trade(self, state):\n",
    "        # Draw random number and see if it is less than epsilon\n",
    "        if random.random() <= self.epsilon:\n",
    "            # random action\n",
    "            return random.randrange(self.action_space)\n",
    "    \n",
    "        # Get the action from the model\n",
    "        action = self.model.predict(state)\n",
    "        \n",
    "    def batch_train(self, batch_size):\n",
    "        # batch starts empty\n",
    "        batch = []\n",
    "        # Cycle through the memory, append batches to the batch list\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "            batch.append(self.memory[i])\n",
    "        \n",
    "        # Get the reward from each batch\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            reward = reward\n",
    "        \n",
    "            if not done:\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            \n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "    \n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "    \n",
    "        if self.epsilon > self.epsilon_final:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now initialize the AI_Trader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 11,171\n",
      "Trainable params: 11,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(state_size = window_size)\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hunting down a few typos and errors (which are not in the final version, so you can't see them any more!), the AI_Trader appears to be working exactly as expected. The model looks good, and the AI_Trader should be ready to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is going to iterate through all 1000 **episodes**. In each iteration, it should:\n",
    "\n",
    "1. Bring out the next episode\n",
    "2. Define the initial state using *state_creator*\n",
    "3. Define new variables to track **total_profit** and set initial **trader.inventory=[]**\n",
    "4. Define the **timestep**, where 1 = 1 Day, and define **action**, **next_state**, and **reward**\n",
    "5. Update the **inventory** based on the **action**\n",
    "6. Update **total_profit** based on the **reward**\n",
    "7. Check if this is the last event (sample) in the dataset\n",
    "8. Append the data to the trader's memory with *trader.memory.append()*\n",
    "9. Change the **state** to the **next_state** to continue iterating through the episode\n",
    "10. ***IF*** we've reached the end of the episode (**done == True**), *print* out the **total_profit**\n",
    "\n",
    "That's plenty of stuff. But before the loop does that, we want to check:\n",
    "\n",
    "* If there is more information in the AI_Trader's **memory** than **batch_size**, call *trader.batch_train(batch_size)*\n",
    "* Every 10 episodes, save the model in an H5 file using *trader.model.save()*\n",
    "\n",
    "Now let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/1000\n",
      "AI_Trader bought:  $ 24.632500\n",
      "AI_Trader bought:  $ 24.347500\n",
      "AI_Trader sold:  $ 24.879999 \n",
      "Profit: $ 0.247499\n",
      "AI_Trader sold:  $ 24.165001 \n",
      "Profit: -$ 0.182499\n",
      "AI_Trader bought:  $ 24.860001\n",
      "AI_Trader sold:  $ 23.522499 \n",
      "Profit: -$ 1.337502\n",
      "AI_Trader bought:  $ 24.087500\n",
      "AI_Trader sold:  $ 23.504999 \n",
      "Profit: -$ 0.582500\n",
      "AI_Trader bought:  $ 23.752501\n",
      "AI_Trader sold:  $ 23.567499 \n",
      "Profit: -$ 0.185001\n",
      "AI_Trader bought:  $ 23.424999\n",
      "AI_Trader sold:  $ 23.497499 \n",
      "Profit: $ 0.072500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 36/1257 [00:14<47:03,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 24.219999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1257 [00:32<1:05:22,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 24.172501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 42/1257 [00:35<1:09:30,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 25.132500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 43/1257 [00:39<1:08:32,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 25.187500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 46/1257 [00:49<1:09:35,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 25.467501 \n",
      "Profit: $ 1.247501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1257 [00:57<1:12:58,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 25.280001 \n",
      "Profit: $ 1.107500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1257 [01:03<1:09:18,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 25.565001 \n",
      "Profit: $ 0.432501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 51/1257 [01:06<1:08:17,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 25.629999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 52/1257 [01:11<1:14:14,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 26.145000 \n",
      "Profit: $ 0.957500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 53/1257 [01:14<1:12:34,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 26.492500 \n",
      "Profit: $ 0.862501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 54/1257 [01:18<1:11:49,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader bought:  $ 26.450001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 55/1257 [01:21<1:09:50,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI_Trader sold:  $ 26.480000 \n",
      "Profit: $ 0.029999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 57/1257 [01:29<1:13:36,  3.68s/it]"
     ]
    }
   ],
   "source": [
    "for episode in range(1, episodes+1):\n",
    "    # Indicate Training Status\n",
    "    print('Episode: {}/{}'.format(episode, episodes))\n",
    "    \n",
    "    # Inititalize all the stuff we need in each episode\n",
    "    state = state_creator(data, 0, window_size + 1)\n",
    "    \n",
    "    total_profit = 0\n",
    "    trader.inventory = []\n",
    "    \n",
    "    # Iterate through the episode\n",
    "    for t in tqdm(range(data_samples)):\n",
    "        \n",
    "        # Select the action to take\n",
    "        action = trader.trade(state)\n",
    "        \n",
    "        # Define the next_state\n",
    "        next_state = state_creator(data, t+1, window_size+1)\n",
    "        \n",
    "        # Initialize reward\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1: #Buy\n",
    "            trader.inventory.append(data[t])\n",
    "            print(\"AI_Trader bought: \", stocks_price_format(data[t]))\n",
    "            \n",
    "        elif action == 2 and len(trader.inventory) > 0: #Sell\n",
    "            buy_price = trader.inventory.pop(0)\n",
    "            reward = max(data[t] - buy_price, 0)\n",
    "            total_profit += data[t] - buy_price\n",
    "            print(\"AI_Trader sold: \", stocks_price_format(data[t]), \n",
    "                  \"\\nProfit: \" + stocks_price_format(data[t] - buy_price))\n",
    "        \n",
    "        # Check if the episode is ending\n",
    "        if t == data_samples - 1:\n",
    "            done=True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Append what just happened to memory\n",
    "        trader.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Move state forward\n",
    "        state = next_state\n",
    "        \n",
    "        # If done, print total_profit\n",
    "        if done:\n",
    "            print(\"################################################################\")\n",
    "            print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "            print(\"################################################################\")\n",
    "        \n",
    "        # If too memory is full, retrain on batches\n",
    "        if len(trader.memory) > batch_size:\n",
    "            trader.batch_train(batch_size)\n",
    "            \n",
    "        # Every 10 episodes, save the model\n",
    "        if episode % 10 == 0:\n",
    "            trader.model.save(\"ai_trader_{}.h5\".format(episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
